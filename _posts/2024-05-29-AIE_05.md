---
layout: single

title:  "인공지능윤리 05: AI가 불러올 수 있는 법률 문제 - 국내외 규제 동향"

categories: Ethic

tag: [Ethic]

typora-root-url: ../

toc: true

author_profile: false

sidebar:
    nav: "docs"

# search: false
use_math: true

published: true


---



**글에 들어가기 앞서...**

이 포스팅은 서울시립대학교 인공지능학과 김현준 변호사님의 '**인공지능윤리**' 강좌의 전범위 수업 내용에 대한 정리를 담고 있습니다.



수업 자료 출처: https://uclass.uos.ac.kr/mod/ubboard/article.php?id=275039&bwid=183599









# EU AI Act

<img src="/images/2024-05-29-AIE_05/image-20240530092130700.png" alt="image-20240530092130700" style="zoom:50%;" />

- 그림 출처: https://www.nemko.com/ko/blog/a-quick-dive-into-the-eu-ai-act

EU는 세계 최초로 인공지능 관련 법을 2024년 3월 13일에 통과시켰습니다. 이 법은 4월에 27개국 장관들의 최종 승인을 받으면 관보에 게재되어 발효됩니다. 일부 금지 조항은 6개월 후에 적용되고, 이후 단계적으로 모두 도입되어 2026년 이후 전면 시행될 예정입니다.





## 제정 목적

- **내부 시장을 활성화**하면서 **기본권을 높은 수준으로 보호**합니다.
- **인공지능의 유해성을 경계**하지만, **기술 혁신을 방해하지 않습니다.**
- **고위험 사용자**에게 특별한 의무를 부여합니다.
- 혁신과 보호 사이 균형을 맞춥니다.





## 용어

- **인공지능 시스템**

  - 다양한 수준의 자율성을 기반으로 하는 기계 기반 시스템

  - 입력 데이터로부터 현실 또는 가상 환경에 영향을 끼칠 수 있는 예측 등을 추론합니다.

    

- **위험성 (risk)**

  위해 발생 가능성과 피해의 심각성을 결합한 것입니다.





## 금지되는 행위

- **의도적으로 조작**하거나 **기만적인 기법을** 사용하는 AI 시스템을 시장에 출시하여 **사람이나 집단의 의사결정 능력에 손상을 가해 왜곡된 의사결정을 하게 하는 행위**
- **연령, 장애 또는 특정 사회적 또는 경제적 상황으로 인해 개인 또는 특정 그룹의 취약성을 악용하여 해당 개인 또는 그룹에 속한 사람의 행동을 실질적으로 왜곡**하여 심각한 피해를 입히거나 그럴 가능성이 있는 행동을 유발하는 AI 시스템을 시장에 출시하는 행위
- **자연인의 성격적 특성 등만으로 범죄 가능성을 평가**하는 행위 (단, 직접적으로 범죄 활동에 연결된 사실에 대한 분석에는 이를 적용하지 않음)
- **얼굴 인식 데이터베이스 구축**을 위해 AI를 활용하는 행위
- **인간의 감정을 추론**하는 AI (단, 의료나 안전상의 이유로 활용하는 것은 제외)
- **생체 데이터를 기반으로 사람을 개별적으로 분류하여 인종, 정치적 견해, 직업, 가치관, 성생활, 성적 취향 등을 추론하는 것에 응용**하는 AI (단, 법집행 과정에서 합법적으로 수집된 데이터에는 적용되지 않음)
- 그 외 원격 생체 인식 시스템에 대한 내용들을 포함합니다.





## 고위험군 특별 의무

<img src="/images/2024-05-29-AIE_05/image-20240530092537710.png" alt="image-20240530092537710" style="zoom:50%;" />

- 의료, 교육, 고용, 금융 등 필수적인 공공·민간 서비스와 법집행 등 국가 주요 시스템과 관련된 부분은 고위험군에 해당합니다.
- **사람의 감독을 받아야 하고, 위험 관리 시스템을 구축하는 것도 필수** 의무입니다.
- 고위험 AI를 시장에 출시하려는 기업들은 반드시 **데이터를 공개**하고, **출시 전 적합성 평가 기준을 통과**해야 합니다. **시스템이 수정되었다면 다시 이를 통과해야 합니다.**
- 데이터가 **차별성을 불러올 수 있는지에 대해 감시**합니다.





## 제재 내용

- 사업체 규모, 위반 사항 등에 따라 차별적으로 규정되어 있습니다.
- 법률을 위반하면 위반 유형에 따라 매출액의 1.5%에서 최대 3,500만 유로(약 500억 원) 또는 글로벌 매출의 7%에 해당하는 과징금(administrative fines) 등이 부과될 수 있습니다.
- EU 회원국은 이 법 취지에 따른 국내 처벌, 제재 규정 등을 제정해야 합니다 (법률 실효성 확보를 위하여).
- EU AI Act에서는 행정벌만 규정되어 있으나, EU가 부과한 의무에 따라 EU 회원국은 형사처벌 규정 등을 도입할 필요가 있습니다.
- EU 회원국이 아니더라도 유럽에서 영업을 하려는 기업들은 이 법률의 영향을 받게 됩니다.







# 국내 AI 규제 움직임

국내에도 다양한 AI 규제 움직임이 있었는데요, 각부,  법률안에서의 인공지능을 바라보는 관점, 규제에 대해서 살펴보겠습니다.





## 과기부 AI 윤리기준

과기부에서는 '사람중심의 인공지능' 구현을 위해 지향되어야 할 최고 가치로 '인간성'을 설정하고 있습니다. 그리고 모든 인공지능은 '인간성을 위한 인공지능'을 지향해야 한다고 말합니다.



### 3대 기본원칙

1. 인간 존엄성 원칙
2. 사회의 공공선 원칙
3. 기술의 합목적성 원칙



### 10대 핵심요건

1 인권보장

2 프라이버시 보호 

3 다양성 존중

4 침해금지

5 공공성

6 연대성

7 데이터 관리

8 책임성

9 안전성

10 투명성





## 인공지능 육성 및 신뢰기반 조성등에 관한 법률안

이 법은 인공지능산업의 육성을 도모하면서 인간이 인공지능의 개발·제공 및 이용에 있어서 지켜야 할 윤리적 원칙 등을 규정하여 인공지능을 신뢰할 수 있는 기반을 마련함으로써 인공지능이 산업과 사회 그리고 인간을 위하는 것이 되도록 이바지함을 목적으로 합니다.



### 정의

- 인공지능

  인간이 가진 지적 능력을 전자적 방법으로 구현하기 위한 것입니다.

  

- 특수한 영역에서 활용되는 인공지능

  사람의 생명, 신체에 위험을 줄 수 있거나 부당한 차별 및 편견의 확산 등 인간의 존엄성을 해칠 위험이 있는 인공지능을 의미합니다.



### 내용

- **인공지능사업자의 윤리**

  인간의 기본권을 침해해선 안됩니다.



- **이용자의 윤리**
  - 인공지능을 임의로 변경하지 않고 본래의 목적과 기능에 맞게 이용해야 합니다.
  - 인공지능을 통해 정당한 사유 없이 타인의 이익을 침해하거나 위해를 가하면 안됩니다.



- **인공지능 사회위원회**
  - 인공지능 관련 정책을 심의하기 위해 국무총리 산하 기구로 설치합니다.
  - 중앙행정기관의 장 / 15년 이상 경력의 인공지능 연구자 / 15년 경력 이상의 판검변 등을 위원으로 합니다.



- **기술 혁신**

  인공지능 기술 혁신을 위한 정책적 내용을 담고 있습니다.



- **안정성 통제**

  - 특수활용 인공지능에 대해 상대방이 그 사용에 대해 미리 알 수 있도록 고지해야 할 의무를 부과합니다.

  - 특수활용 인공지능을 개발하고자 하는 자는 과기부 장관에게 미리 신고하여야 합니다.

    

- **제재 조항**

  - 특수활용 인공지능 관련 준수사항을 위반한 경우 벌칙을 부과합니다.
  - 기타 사항 위반에 대해서는 행정벌을 부과합니다.





#  AI 전문가가 가져야 할 자세

**EU AI Act**, 국내 과기부 윤리기준 및 **AI** 법률안의 제정 목적에 공통적으로 드러나는 내용은 **‘인권’을 최우선으로 보호해야 한다는 것**입니다. 기술 혁신은 필요하지만, **AI** 기술 개발 과정에서 인권을 해칠 수 있는 위험성은 최대한 배제해야 합니다.

- **구체적으로 다음 요건에 대한 진지한 성찰 및 경계심이 필요합니다**

  1. 인권 보호

  2. 프라이버시 보호

  3. 다양성 존중

  4. 차별성 배제

  5. 데이터의 투명성

  6. 안전성

  7. 책임감

     

- **AI 연구자, 개발자, 관리자, 이용자 모두가 위와 같은 윤리기준을 명심해야 합니다.** AI는 그 특성상 짧은 시간에 막대한 피해를 입힐 수 있으므로 기존의 사례와는 구분되는 차별성을 지니고 있습니다. 그러므로 위험성에 대하여 늘 경계해야 합니다.