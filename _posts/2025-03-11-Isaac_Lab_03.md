---
layout: single

title:  "Isaac Lab 강화학습"

categories: Isaac_Lab

tag: [Simulator, Reinforcement_Learning]

typora-root-url: ../

toc: true

author_profile: false

sidebar:
    nav: "docs"

# search: false
use_math: true
published: True

---





이 포스팅은 '**Isaac Lab**'에 대한 내용을 담고 있습니다.



자료 출처: <https://isaac-sim.github.io/IsaacLab/main/source/tutorials/index.html>









# Isaac Lab 강화학습

이제 Isaac Lab에서 강화학습을 수행하는 방법에 대해 살펴봅니다. 강화학습을 하기에 앞서 여러 환경을 한꺼번에 생성하는 방법을 먼저 살펴보겠습니다.







## [Manager-Based Base Environment](https://isaac-sim.github.io/IsaacLab/main/source/tutorials/03_envs/create_manager_base_env.html)

```python
# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
# All rights reserved.
#
# SPDX-License-Identifier: BSD-3-Clause

"""
This script demonstrates how to create a simple environment with a cartpole. It combines the concepts of
scene, action, observation and event managers to create an environment.
"""

"""Launch Isaac Sim Simulator first."""


import argparse

from isaaclab.app import AppLauncher

# add argparse arguments
parser = argparse.ArgumentParser(description="Tutorial on creating a cartpole base environment.")
parser.add_argument("--num_envs", type=int, default=16, help="Number of environments to spawn.")

# append AppLauncher cli args
AppLauncher.add_app_launcher_args(parser)
# parse the arguments
args_cli = parser.parse_args()

# launch omniverse app
app_launcher = AppLauncher(args_cli)
simulation_app = app_launcher.app

"""Rest everything follows."""

import math
import torch

import isaaclab.envs.mdp as mdp
from isaaclab.envs import ManagerBasedEnv, ManagerBasedEnvCfg
from isaaclab.managers import EventTermCfg as EventTerm
from isaaclab.managers import ObservationGroupCfg as ObsGroup
from isaaclab.managers import ObservationTermCfg as ObsTerm
from isaaclab.managers import SceneEntityCfg
from isaaclab.utils import configclass



from isaaclab.scene import InteractiveScene, InteractiveSceneCfg
from isaaclab_assets import CARTPOLE_CFG 
from isaaclab.assets import ArticulationCfg, AssetBaseCfg
import isaaclab.sim as sim_utils
@configclass
class CartpoleSceneCfg(InteractiveSceneCfg):
    """Configuration for a cart-pole scene."""

    # ground plane
    ground = AssetBaseCfg(
        prim_path="/World/ground",
        spawn=sim_utils.GroundPlaneCfg(size=(100.0, 100.0)),
    )

    # cartpole
    robot: ArticulationCfg = CARTPOLE_CFG.replace(prim_path="{ENV_REGEX_NS}/Robot")

    # lights
    dome_light = AssetBaseCfg(
        prim_path="/World/DomeLight",
        spawn=sim_utils.DomeLightCfg(color=(0.9, 0.9, 0.9), intensity=500.0),
    )

@configclass
class ActionsCfg:
    """Action specifications for the environment."""

    joint_efforts = mdp.JointEffortActionCfg(asset_name="robot", joint_names=["slider_to_cart"], scale=5.0)


@configclass
class ObservationsCfg:
    """Observation specifications for the environment."""

    @configclass
    class PolicyCfg(ObsGroup):
        """Observations for policy group."""

        # observation terms (order preserved)
        joint_pos_rel = ObsTerm(func=mdp.joint_pos_rel)
        joint_vel_rel = ObsTerm(func=mdp.joint_vel_rel)

        def __post_init__(self) -> None:
            self.enable_corruption = False
            self.concatenate_terms = True

    # observation groups
    policy: PolicyCfg = PolicyCfg()


@configclass
class EventCfg:
    """Configuration for events."""

    # on startup
    add_pole_mass = EventTerm(
        func=mdp.randomize_rigid_body_mass,
        mode="startup",
        params={
            "asset_cfg": SceneEntityCfg("robot", body_names=["pole"]),
            "mass_distribution_params": (0.1, 0.5),
            "operation": "add",
        },
    )

    # on reset
    reset_cart_position = EventTerm(
        func=mdp.reset_joints_by_offset,
        mode="reset",
        params={
            "asset_cfg": SceneEntityCfg("robot", joint_names=["slider_to_cart"]),
            "position_range": (-1.0, 1.0),
            "velocity_range": (-0.1, 0.1),
        },
    )

    reset_pole_position = EventTerm(
        func=mdp.reset_joints_by_offset,
        mode="reset",
        params={
            "asset_cfg": SceneEntityCfg("robot", joint_names=["cart_to_pole"]),
            "position_range": (-0.125 * math.pi, 0.125 * math.pi),
            "velocity_range": (-0.01 * math.pi, 0.01 * math.pi),
        },
    )


@configclass
class CartpoleEnvCfg(ManagerBasedEnvCfg):
    """Configuration for the cartpole environment."""

    # Scene settings
    scene = CartpoleSceneCfg(num_envs=1024, env_spacing=2.5)
    # Basic settings
    observations = ObservationsCfg()
    actions = ActionsCfg()
    events = EventCfg()

    def __post_init__(self):
        """Post initialization."""
        # viewer settings
        self.viewer.eye = [4.5, 0.0, 6.0]
        self.viewer.lookat = [0.0, 0.0, 2.0]
        # step settings
        self.decimation = 4  # env step every 4 sim steps: 200Hz / 4 = 50Hz
        # simulation settings
        self.sim.dt = 0.005  # sim step every 5ms: 200Hz


def main():
    """Main function."""
    # parse the arguments
    env_cfg = CartpoleEnvCfg()
    env_cfg.scene.num_envs = args_cli.num_envs
    # setup base environment
    env = ManagerBasedEnv(cfg=env_cfg)

    # simulate physics
    count = 0
    while simulation_app.is_running():
        with torch.inference_mode():
            # reset
            if count % 300 == 0:
                count = 0
                env.reset()
                print("-" * 80)
                print("[INFO]: Resetting environment...")
            # sample random actions
            joint_efforts = torch.randn_like(env.action_manager.action)
            # step the environment
            obs, _ = env.step(joint_efforts)
            # print current orientation of pole
            print("[Env 0]: Pole joint: ", obs["policy"][0][1].item())
            # update counter
            count += 1

    # close the environment
    env.close()


if __name__ == "__main__":
    # run the main function
    main()
    # close sim app
    simulation_app.close()
```

Isaac Lab에서 환경을 작성하는 방법은 크게 2가지가 있습니다. 하나는 **Manager-Based** 방식이고, 다른 하나는 **Direct Workflow** 방식입니다. 두 가지 방식으로 환경을 작성하는 방법을 모두 다룰건데, 튜토리얼의 순서대로 Manager-Based 방식 먼저 다루겠습니다. 위 파이썬 코드가 바로 Manager-Based 스타일로 적힌 코드입니다. 튜토리얼 코드랑 조금 차이가 있는데, 바로 아래의 Designing Scene 부분을 튜토리얼에서는 별도 파일로 따로 빼 설명합니다. 그런데 이 코드에서는 그 부분을 가져와 함께 적어두었습니다.





### Designing Scene

```python
from isaaclab.scene import InteractiveScene, InteractiveSceneCfg
from isaaclab_assets import CARTPOLE_CFG 
from isaaclab.assets import ArticulationCfg, AssetBaseCfg
import isaaclab.sim as sim_utils
@configclass
class CartpoleSceneCfg(InteractiveSceneCfg):
    """Configuration for a cart-pole scene."""

    # ground plane
    ground = AssetBaseCfg(
        prim_path="/World/ground",
        spawn=sim_utils.GroundPlaneCfg(size=(100.0, 100.0)),
    )

    # cartpole
    robot: ArticulationCfg = CARTPOLE_CFG.replace(prim_path="{ENV_REGEX_NS}/Robot")

    # lights
    dome_light = AssetBaseCfg(
        prim_path="/World/DomeLight",
        spawn=sim_utils.DomeLightCfg(color=(0.9, 0.9, 0.9), intensity=500.0),
    )
```

일단 병렬화하고자 하는 환경의 모양새를 결정합니다. 환경 configuration환경을 만들 때는 위와 같이 `InteractiveSceneCfg`를 상속받도록 해줍니다. 평면이랑 조명같은 경우에 CartPole 환경에서 물리적 상호작용을 하지 않을 뿐더러, 그렇다 하더라도 정적 요소이므로 `AssetBaseCfg`로 설정합니다. CartPole의 경우 동적으로 계속 변하는 개체이기 때문에 `ArticulationCfg`로 설정해 동적인 상호작용을 할 수 있도록 합니다.





### Action

```python
@configclass
class ActionsCfg:
    """Action specifications for the environment."""

    joint_efforts = mdp.JointEffortActionCfg(asset_name="robot", joint_names=["slider_to_cart"], scale=5.0)
```

이전에는 `set_joint_effort_target(efforts)`를 사용해 액션을 전달했는데, 위와 같이 클래스를 선언해두면 `action_manager`를 사용해 액션을 조절할 수 있습니다. 위는 CartPole 예시이기 때문에 `joint_efforts`만 있는데, 액션이 여러 개인 경우 여러 액션 변수가 있을 수 있습니다.





### Observation

```python
@configclass
class ObservationsCfg:
    """Observation specifications for the environment."""

    @configclass
    class PolicyCfg(ObsGroup):
        """Observations for policy group."""

        # observation terms (order preserved)
        joint_pos_rel = ObsTerm(func=mdp.joint_pos_rel)
        joint_vel_rel = ObsTerm(func=mdp.joint_vel_rel)

        def __post_init__(self) -> None:
            self.enable_corruption = False
            self.concatenate_terms = True

    # observation groups
    policy: PolicyCfg = PolicyCfg()

```

에이전트가 환경을 어떻게 관측할지를 결정합니다. 클래스 내부에 `PolicyCfg`라는 클래스를 따로 만들어서, 행동 선택에 필요한 관측 데이터를 모아둡니다. 관측 정보로는 상대 관절 위치와, 상대 관절 속도를 저장합니다. `__post_init__` 함수가 선언되어 있는데, 이는 클래스 초기화 이후에 실행되는 함수입니다. `enable_corruption`은 데이터에 인위적인 왜곡을 추가할 것인지를 선택하는 옵션이고, 그 아래 `concatenate_terms`는 관측 정보들을 하나로 concat한 벡터로 다룰 것인지를 선택하는 옵션입니다. 마지막으로 `ObservationsCfg`는 `policy`라는 이름의 속성을 가지게 됩니다.





### Event

```python
@configclass
class EventCfg:
    """Configuration for events."""

    # on startup
    add_pole_mass = EventTerm(
        func=mdp.randomize_rigid_body_mass,
        mode="startup",
        params={
            "asset_cfg": SceneEntityCfg("robot", body_names=["pole"]),
            "mass_distribution_params": (0.1, 0.5),
            "operation": "add",
        },
    )

    # on reset
    reset_cart_position = EventTerm(
        func=mdp.reset_joints_by_offset,
        mode="reset",
        params={
            "asset_cfg": SceneEntityCfg("robot", joint_names=["slider_to_cart"]),
            "position_range": (-1.0, 1.0),
            "velocity_range": (-0.1, 0.1),
        },
    )

    reset_pole_position = EventTerm(
        func=mdp.reset_joints_by_offset,
        mode="reset",
        params={
            "asset_cfg": SceneEntityCfg("robot", joint_names=["cart_to_pole"]),
            "position_range": (-0.125 * math.pi, 0.125 * math.pi),
            "velocity_range": (-0.01 * math.pi, 0.01 * math.pi),
        },
    )
```

`EventCfg`는 특정 이벤트가 발생했을 때 실행해야 하는 동작들을 포함합니다. `mode`의 종류에는 `"startup"`, `"reset"`, `"interval"`이 있고, 각각은 환경 시작 시 발생하는 이벤트, 환경 종료, 재설정 시 발생하는 이벤트, 지정된 간격으로 실행되는 이벤트를 의미합니다. 





### Connect

```python
@configclass
class CartpoleEnvCfg(ManagerBasedEnvCfg):
    """Configuration for the cartpole environment."""

    # Scene settings
    scene = CartpoleSceneCfg(num_envs=1024, env_spacing=2.5)
    # Basic settings
    observations = ObservationsCfg()
    actions = ActionsCfg()
    events = EventCfg()

    def __post_init__(self):
        """Post initialization."""
        # viewer settings
        self.viewer.eye = [4.5, 0.0, 6.0]
        self.viewer.lookat = [0.0, 0.0, 2.0]
        # step settings
        self.decimation = 4  # env step every 4 sim steps: 200Hz / 4 = 50Hz
        # simulation settings
        self.sim.dt = 0.005  # sim step every 5ms: 200Hz
```

위에서 정의한 클래스들을 모두 한데 모아 하나의 클래스로 구성합니다. 위의 `decimation`은 환경 스텝 갱신 간격을 의미합니다. 





### main

```python
def main():
    """Main function."""
    # parse the arguments
    env_cfg = CartpoleEnvCfg()
    env_cfg.scene.num_envs = args_cli.num_envs
    # setup base environment
    env = ManagerBasedEnv(cfg=env_cfg)

    # simulate physics
    count = 0
    while simulation_app.is_running():
        with torch.inference_mode():
            # reset
            if count % 300 == 0:
                count = 0
                env.reset()
                print("-" * 80)
                print("[INFO]: Resetting environment...")
            # sample random actions
            joint_efforts = torch.randn_like(env.action_manager.action)
            # step the environment
            obs, _ = env.step(joint_efforts)
            # print current orientation of pole
            print("[Env 0]: Pole joint: ", obs["policy"][0][1].item())
            # update counter
            count += 1

    # close the environment
    env.close()
```

마지막으로 `main()`에서 configuration 클래스 객체를 선언하고, configuration 객체를 인자로 넣어 `ManagerBasedEnv`의 환경 객체를 만들어줍니다. 그리고 이어지는 코드를 통해 환경을 실행시키면 아래와 같은 화면을 볼 수 있습니다.



![image (29)](/images/2025-03-11-Isaac_Lab_03/image (29).png)







## [Direct Workflow RL Environment](https://isaac-sim.github.io/IsaacLab/main/source/tutorials/03_envs/create_direct_rl_env.html)



