---
layout: single

title:  "CS231n: Introduction to CNN for Visual Recognition"

categories: Computer_Vision

tag: [CV]

typora-root-url: ../

toc: true

author_profile: false

sidebar:
    nav: "docs"

# search: false
use_math: true
published: True

---





이 포스팅은 '**CS231n의 Lecture 01~03**'에 대한 내용을 담고 있습니다.



자료 출처

- <https://www.youtube.com/watch?v=vT1JzLTH4G4>
- <https://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture1.pdf>









# Computer Vision

먼저 이 강의 전반에서 다루는 주제인 Computer Vision이 무엇인지 살펴봅니다. 이후 Image Classification의 전통적인 방법론들, 그리고 손실 함수와 최적화에 대해 알아봅시다.







## Introduction

시각 정보는 생명체가 수집하는 정보들 중 가장 큰 부분을 차지합니다. 이러한 시각 정보들을 담아내기 위한 Camera Obscura와 렌즈 등 다양한 발명품들이 있었고, 이렇게 수집한 수많은 이미지들을 인터넷에서 확인할 수 있습니다. 

이런 시각 정보를 컴퓨터에게 '이해'시키는 것은 지난 반세기 동안 정말 해결하기 어렵고 난해한 분야였습니다. 하지만 지금에 이르러서는 인간보다도 높은 정확도를 보이기도 합니다. 그만큼 정말 빠른 속도로 발전한 분야이고, 그동안 정말 많은 접근 방법들과 시행착오 끝에 현재는 머신러닝을 기반으로 한 Image Classificaiton이 가장 주를 이루고 있습니다.







## Image Classification Pipeline

![cat](/images/2025-07-20-CS231n_01/cat.png)

인간이라면 위 사진을 보고 바로 고양이라고 대답할 수 있습니다(고양이를 본 적이 있는 사람이라면). 인간이 어떠한 물체의 사진을 보고 카테고리를 분류하는 데에는 분명히 어떠한 공통된 방법이 존재할 텐데요, 그게 뭔지 정확하게 기술하는 것은 거의 불가능한 일입니다. 과거 행해졌던 방법 중 물체의 모서리와 코너를 감지하고 '고양이 카테고리에 해당하는 사진들의 모서리, 코너들은 이러이러한 분포를 가질거야'라는 식의 특정 카테고리마다 모서리와 코너의 분포 양상을 기술해보려는 시도가 있었습니다. 당시 꽤나 강력한 지지를 받고 많은 연구가 있었지만, 결론적으로는 택도 없는 방법이라는 결론에 도달했습니다.



![image-20250721000511866](/images/2025-07-20-CS231n_01/image-20250721000511866.png)

물체의 카테고리를 구별해내는 것은 컴퓨터에게 있어 생각 이상으로 어려운 일입니다. 이는 하나의 카테고리에 해당되는 객체들이 정말 다양하게 존재한다는 점에 기인합니다. 위와 같이 조명 조건에 따라서도..





![image-20250721000525591](/images/2025-07-20-CS231n_01/image-20250721000525591.png)

물체의 자세에 따라서도..



![image-20250721000542297](/images/2025-07-20-CS231n_01/image-20250721000542297.png)

물체를 가리고 있는 배경에 따라서도..



<img src="/images/2025-07-20-CS231n_01/image-20250721000604558.png" alt="image-20250721000604558" style="zoom:30%;" />

그리고 같은 고양이라고 해도 세부 품종에 따라 이미지에 정말 다양한 픽셀값으로 나타나게 됩니다. 이 수많은 사진들 중 고양이 카테고리만이 가지는 공통된 특징을 통해 고양이 사진을 분류해내는 알고리즘을 적어내는 것은 거의 불가능한 일입니다. 이러한 문제점을 바탕으로 모든 카테고리들에 대해 공통적으로 적용할 수 있는 '**데이터 기반 접근 방식**(Date-Driven Approach)'이 새롭게 등장하게 됩니다.





### Data-Driven Approach

가장 대표적인 데이터 기반 접근 방식으로는 K-Nearest Neighbors(KNN)이 있습니다.



#### K-Nearset Neighbors

```python
import numpy as np
from sklearn.datasets import make_blobs
from collections import Counter

import matplotlib.pyplot as plt

# Generate a 2D dataset
np.random.seed(42)
X, y = make_blobs(n_samples=90, centers=3, n_features=2, random_state=42)

# Adjust feature values' range to ensure the minimum value is 1.0
X_min = X.min(axis=0)
X += (1.0 - X_min)

# Plot the dataset
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', s=50)
plt.title("Generated 2D Dataset")
plt.xlabel('leaf length')
plt.ylabel('leaf width')
plt.show()

# k-NN algorithm
def knn_classify(X_train, y_train, X_test, k):
    predictions = []
    for i, test_point in enumerate(X_test):
        # Compute distances from the test point to all training points
        distances = np.linalg.norm(X_train - test_point, axis=1)
        
        # Get the indices of the k nearest neighbors
        k_indices = np.argsort(distances)[:k]
        
        # Get the labels of the k nearest neighbors
        k_labels = y_train[k_indices]
        
        # Determine the most common label
        most_common = Counter(k_labels).most_common(1)[0][0]
        predictions.append(most_common)
        
        # Visualization of progress
        plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='viridis', s=50, alpha=0.5)
        plt.scatter(test_point[0], test_point[1], c='red', s=100, label='Test Point')
        plt.scatter(X_train[k_indices, 0], X_train[k_indices, 1], edgecolor='black', facecolor='none', s=200, label='Neighbors')
        plt.title(f"Iteration {i+1}: Classifying Test Point")
        plt.legend()
        plt.xlabel('leaf length')
        plt.ylabel('leaf width')
        plt.show()
        
    return np.array(predictions)

# Split the dataset into training and test sets
train_size = int(0.8 * len(X))
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Run k-NN with k=5
k = 5
y_pred = knn_classify(X_train, y_train, X_test, k)

# Print the predictions
print("Predicted labels:", y_pred)
print("True labels:", y_test)
```

KNN 알고리즘의 과정은 굉장히 간단하고도 직관적입니다. KNN 알고리즘을 통해 분류를 하기 위해서는 먼저 학습 데이터가 필요합니다. 그리고 이 학습 데이터를 통해 우리가 구분하고자 하는 미관찰 데이터를 분류하게 되는데요, 그 과정은 아래와 같습니다.

예시로 우리가 식물의 종류를 분류해야하는 상황을 가정해봅니다. 단, 여기서 우리가 사용할 수 있는 단서는 잎의 길이와 넓이, 이 두가지 특징 뿐입니다. 총 세 개의 식물 종이 있고, 각 식물 종마다 서른 개의 학습 데이터가 주어집니다(학습 데이터라는 용어가 사용되기는 하지만, 우리가 흔히 생각하는 학습이라는 행위거 이 알고리즘에서 수행되진 않습니다. 머신러닝, 인공지능 분야에서는 실제 테스트에 앞서 알고리즘이 필요로하는 데이터를 나이브하게 학습 데이터라고 부르는 관습이 있습니다). 우리가 가진 90개의 모든 학습 데이터를 좌표평면에 찍어보겠습니다.



![image-20250721012153695](/images/2025-07-20-CS231n_01/image-20250721012153695.png)

같은 종의 식물들 끼리는 비슷한 잎의 형상을 가질 것입니다. 따라서 학습 데이터들을 찍어보면 같은 종에 속하는 객체들끼리 군집을 이루게 됩니다. 



![image-20250721012239568](/images/2025-07-20-CS231n_01/image-20250721012239568.png)

다음으로 우리가 실제로 구분하고자 하는 테스트 데이터를 좌표평면 상에 찍습니다. 그리고 그 점과 가장 가까운 K개의 이웃하는 학습 데이터들의 카테고리를 확인합니다. K값을 5라고 해보겠습니다. 위의 그림에서는 테스트 데이터가 초록색 카테고리의 한 가운데에 위치하는데, 이 경우 이웃하는 5개의 학습 데이터의 카테고리는 모두 '초록색'입니다. 따라서 테스트 데이터의 카테고리를 '초록색'으로 결정합니다. 이것이 KNN 알고리즘의 수행 과정입니다.

위 경우에서는 이웃하는 5개의 학습 데이터가 모두 초록색이었습니다. 하지만 세 군집 그 가운데 애매한 곳에 테스트 데이터가 존재할 수도 있습니다. 이 경우 당연하게도 5개의 이웃하는 학습 데이터 중 가장 많은 수가 속한 카테고리로 테스트 데이터를 분류합니다.

용어를 하나 소개하자면 인공지능, 머신러닝 분야에서는 카테고리를 레이블(Label)이라고 부릅니다. 예시로 튤립 레이블, 나팔꽃 레이블, 장미 레이블.. 이런식으로 부릅니다. 이후 문서에서는 카테고리라는 일반적인 용어 대신 레이블이라고 표현하겠습니다.



```python
import numpy as np
from sklearn.datasets import make_blobs
from collections import Counter

import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap

# Generate a 2D dataset with more overlap between clusters
np.random.seed(42)
X, y = make_blobs(n_samples=90, centers=3, n_features=2, cluster_std=5.0, random_state=42)

# Adjust feature values' range to ensure the minimum value is 1.0
X_min = X.min(axis=0)
X += (1.0 - X_min)

# Plot the dataset
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', s=50)
plt.title("Generated 2D Dataset")
plt.xlabel('leaf length')
plt.ylabel('leaf width')
plt.show()

# k-NN algorithm
def knn_classify(X_train, y_train, X_test, k):
    predictions = []
    for i, test_point in enumerate(X_test):
        # Compute distances from the test point to all training points
        distances = np.linalg.norm(X_train - test_point, axis=1)
        
        # Get the indices of the k nearest neighbors
        k_indices = np.argsort(distances)[:k]
        
        # Get the labels of the k nearest neighbors
        k_labels = y_train[k_indices]
        
        # Determine the most common label
        most_common = Counter(k_labels).most_common(1)[0][0]
        predictions.append(most_common)
        
    return np.array(predictions)

# Function to plot decision boundaries for all points at once
def plot_decision_boundary(X, y, k):
    h = 0.1  # Step size in the mesh
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
    
    # Predict labels for each point in the mesh
    Z = knn_classify(X, y, np.c_[xx.ravel(), yy.ravel()], k)
    Z = Z.reshape(xx.shape)
    
    # Plot the decision boundary
    plt.figure()
    plt.contourf(xx, yy, Z, alpha=0.3, cmap=ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF']))
    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', edgecolor='k', s=50)
    plt.title(f"Decision Boundary (k={k})")
    plt.xlabel('leaf length')
    plt.ylabel('leaf width')
    plt.show()

# Split the dataset into training and test sets
train_size = int(0.8 * len(X))
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Run k-NN with k=5
k = 5
y_pred = knn_classify(X_train, y_train, X_test, k)

# Print the predictions
print("Predicted labels:", y_pred)
print("True labels:", y_test)

# Visualize decision boundaries for different values of k
k_values = [1, 3, 5, 7, 9, 11, 13]
for k in k_values:
    plot_decision_boundary(X_train, y_train, k)
```

K의 값을 5라고 설정할 수도, 7이라고 설정할 수도, 혹은 그 외의 다른 어떠한 숫자로 결정해도 괜찮습니다. 다만 이 값을 홀수로 설정하는 관습이 존재합니다(레이블 개수가 2개일 때 동률이 발생하지 않도록 하기 위해 이 K값을 홀수로 설정하지만, 사실 레이블 개수가 3개 이상부터는 큰 의미가 없습니다). 당연히 K값에 따라서 테스트 데이터의 분류 레이블이 바뀔 수 있습니다. 3개일 때 [초, 초, 빨] 이었는데, 5개일 때 [초, 초, 빨, 빨, 빨]일 수 있다는 거죠. 위 코드를 실행시켜 K 값에 따른 분류 레이블의 경계를 확인해볼 수 있습니다.



![image-20250721020323103](/images/2025-07-20-CS231n_01/image-20250721020323103.png)

3개의 레이블로 구성된 학습 데이터들이 조금 겹치게 분포한 모습입니다(실제 현실세계에서는 위와 같이 레이블의 분포가 겹쳐 나타나는 경우가 일반적입니다). 



![image-20250721020333719](/images/2025-07-20-CS231n_01/image-20250721020333719.png)

K가 1일 때..



![image-20250721020447413](/images/2025-07-20-CS231n_01/image-20250721020447413.png)

K가 3일 때..



![image-20250721020456938](/images/2025-07-20-CS231n_01/image-20250721020456938.png)

K가 5일 때..



![image-20250721020505998](/images/2025-07-20-CS231n_01/image-20250721020505998.png)

K가 7일 때 모습입니다. 어째서 조금씩 경계가 부드러워지는 경향성을 확인할 수 있습니다. 경계가 이리저리 들쭉날쭉 한 것 보다는 각 레이블에 해당하는 점들의 중심 기준으로 부드러운 경계가 그려진 모습이 우리의 직관과 더 맞는 '올바른 경계'일 가능성이 높습니다. 각 레이블의 학습 데이터 개수가 30개 밖에 되지 않기 때문에 어느정도 편향이 있을 수밖에 없거든요. K가 극단적으로 낮게 설정되면 테스트 데이터를 분류할 때 이 학습 데이터에 지나치게 의존하게 됩니다. 

그 예시로 K가 1일 때, 빨간색 점들의 영역 한가운데에 보라색과 초록색 레이블 영역이 외딴 섬처럼 존재하는 것을 확인할 수 있습니다. 빨간색 레이블 사이에 존재하는 보라색, 초록색 학습 데이터의 주위를 각 해당 레이블의 바운더리에 포함시키는 것보다는 레이블 분포에서 벗어난 '이상치'라고 해석하는 것이 합리적입니다. 



![image-20250721021104687](/images/2025-07-20-CS231n_01/image-20250721021104687.png) 

그렇다고 K값이 무조건 크다고 좋은 것은 아닙니다. K값이 계속 커지다 보면 위와 같이 데이터의 분포를 정확하게 해석하지 못하게 됩니다. 따라서 학습 데이터로부터 올바른 경계를 뽑아낼 수 있도록 적당한 K값을 결정하는게 KNN 알고리즘에서는 가장 중요한 부분입니다.



이렇게 알고리즘에서 우리가 직접 정해줘야하는 상수를 하이퍼파라미터(Hyperparameter)라고 부릅니다. 이 하이퍼파라미터는 모집단을 대표하는 테스트 데이터를 적절히 분류하도록 설정되어야 하지만, 테스트 데이터를 보고 결정해서는 안됩니다. 왜냐면 테스트 데이터도 개수가 한정되어있을 수밖에 없는데(당연히 편향이 존재하겠죠?), 이걸 보고 하이퍼파라미터를 결정해봤자 결국 이 역시 편향이 포함된 어떤 데이터 집단을 보고 결정한 것에 지나지 않습니다. 다시 말하면, 지금 우리가 가지고 있는 테스트 데이터에서는 잘한다지만, 또 다른 테스트 데이터를 가지고 왔을 때에도 잘할 수 있을지는 보장할 수 없습니다. 요런 문제점을 해결하기 위해서 학습 데이터 모두를 사용하지 않고, 그 중 일부를 Validation Set으로 따로 떼어놓는 전략을 사용합니다.



![image-20250721024429768](/images/2025-07-20-CS231n_01/image-20250721024429768.png)

Training Set은 모델을 학습시킬 때 사용하고 Validation Set을 가장 잘 설명할 수 있는 값으로 하이퍼파라미터를 설정합니다. 이후 Test Set으로 모델의 정확한 성능을 평가합니다. Validation Set를 빼놓는 이유가 Test Set을 사용해 모델의 정확한 성능을 평가하기 위함인 만큼, Test Set은 학습 과정에 있어서 절대로 사용하지 않아야 합니다.



KNN 알고리즘은 정말 단순하고도 강력한 도구인데요, 아쉽게도 이미지를 분류할 때 사용하기는 어렵습니다. 첫 번째로 KNN 알고리즘은 학습 데이터를 저장하고 있어야 합니다. 학습 데이터 편향을 낮추려면 가능한 많은 데이터를 가지고 있어야 하는데, 이 자체가 큰 부담이 됩니다. 그리고 인간이야 좌표평면을 보고 가까운 학습 데이터들을 바로 파악할 수 있지만, 컴퓨터는 모든 학습 데이터들과 거리를 측정해 본 후에야 가장 가까웠던 학습 데이터들을 알 수 있기 때문에 학습데이터가 많아지면 많아질수록 알고리즘의 수행시간이 늘어나게 됩니다. 

두 번째는 차원의 저주(Curse of Dimensionality)입니다. 이미지 데이터에서는 픽셀 하나하나가 특징이 되고, 각 특징이 한 개의 차원이 되기 때문에 가로 세로 28픽셀의 흑백 이미지 데이터도 784라는 무시무시한 차원을 가지게 됩니다. 그런데 데이터 존재하는 차원의 커지면 커질수록 그 공간에 존재하는 데이터들 사이의 거리가 다 비슷비슷해지게 현상이 있는데, 이를 차원의 저주라고 부릅니다. 이 현상으로 인해 가장 가까운 학습 데이터 이웃의 레이블로 테스트 데이터의 레이블을 분류하는 KNN 알고리즘이 잘 동작하지 않게 됩니다. 



#### Linear Classification

또 다른 대표적인 데이터 기반 접근 방식으로 **선형 분류**(Linear Classification)가 있습니다.



![image-20250721103953578](/images/2025-07-20-CS231n_01/image-20250721103953578.png)

예시로 4 픽셀짜리 사진을 분류하는 상황을 생각해봅시다. 위와 같이 2 by 2로 나타난 고양이 사진을 일렬로 펴 [56, 231, 24, 2] 라는 벡터로 표현할 수 있습니다. 이 벡터에 가중치 행렬($W$)을 곱해 3차원으로 선형변환을 해준 다음 3차원 편향 벡터를 더해줍니다. 마지막 결과 벡터에서 가장 큰 값을 가지고 있는 인덱스를 해당 이미지의 레이블로 결정합니다. 



![image-20250721105544794](/images/2025-07-20-CS231n_01/image-20250721105544794.png)

이 모든 과정들을 좀 더 간단히 위와 같이 표현할 수 있는 거구요, 레이블의 개수가 더 많을 때에도 몇 차원으로 선형 변환 시키느냐만 다를 뿐 나머지 부분들은 동일합니다.



![linear_trans](/images/2025-07-20-CS231n_01/linear_trans.gif)

- <https://www.youtube.com/watch?v=XkY2DOUCWMU>

선형 분류가 조금 더 복잡하기는 해도 정말 잘 동작하는데, 이 알고리즘에도 해결되지 않는 문제점이 있습니다. 선형 변환은 위의 gif처럼 공간상에서 늘리고 줄이고 돌리는게 가능하지만, 처음에 평행했던 성분은 변환 이후에도 평행이 유지된다는 특징이 있습니다. 



<img src="/images/2025-07-20-CS231n_01/image-20250721113026326.png" alt="image-20250721113026326" style="zoom:33%;" />

그런데 만약에 애당초 **이미지 벡터 공간상에** 고양이 레이블과 개 레이블이 저렇게 **휘어있는** 분포를 가졌다면, 이거를 아무리 선형변환을 하더라도 반듯하게 펴는 것이 불가능합니다. 



또, 어쨎든 선형변환을 하려면 가장 적절한 $W$와 $b$값을 찾아야하는데, 고양이 사진을 4픽셀로 단순화시킨 상황에서도 15개의 값을 찾아야하니 15차원 공간에서 탐색해야한다는 얘긴데, 이것도 굉장히 쉽지 않은 일입니다. 



#### Loss Function

휘어있는 분포를 어떻게 다루는가 이전에(다음 포스팅에서 다룹니다), 가장 적절한 $W$와 $b$값을 찾는 방법에 대해서 알아봅시다.



<img src="/images/2025-07-20-CS231n_01/image-20250721132433712.png" alt="image-20250721132433712" style="zoom:30%;" />

고양이 사진에 대해서 고양이 레이블 점수가 3.2, 자동차 레이블 점수가 5.1으로 고양이 사진을 보고 자동차 사진이라고 분류해놨습니다.. 자동차 사진은 올바르게 분류하긴 했는데요, 개구리 사진은 개구리 레이블 점수가 가장 낮네요. 아무튼 완전 엉터리로 분류기가 돌아가고 있는데, 일단 분류기의 성능을 높이기 위해서는 분류기가 얼마만큼 잘하는지를 정량적으로 평가할 수 있어야 합니다. 다시 말해, 현재 분류기(구체적으로는 분류기를 구성하는 $W$와 $b$)의 불량도를 정량적으로 측정하는 함수가 필요한데, 이를 **손실 함수**(Loss Function)라고 부릅니다. 손실 함수를 선정해 분류기의 불량도를 정량적으로 측정함으로써 $W$와 $b$의 모든 공간에서 가장 좋은 조합이 무엇인지 찾아나가는 효율적인 절차를 찾아야 합니다(모든 공간을 싹 다 탐색하기에는 너무 넓기 때문이죠). 이를 **최적화**(Optimization)이라고 부르고 문서 후반에 그 내용을 다룹니다.


$$
\{(x_i, y_i)\}^{N}_{i=1}
$$


분류기의 잘하고 못한 정도를 판단하기 위해서는 먼저 데이터셋이 필요합니다. 실제로 고양이 사진을 넣어보고, 차 사진을 넣어봐야 이 분류기가 얼만큼 잘 동작하는지 알 수 있죠. 위의 데이터셋에서 $x_i$는 이미지, $y_i$는 이미지에 대응되는 정답 레이블(고양이 사진이면 '고양이', 강아지 사진이면 '강아지')입니다. 


$$
s = f(x_i, W) = [s_0, s_1, ...]
$$


위에서 $W$는 일반적으로 모델에서 사용되는 모든 파라미터(가중치 벡터와 편향치)를 대표합니다.  위의 고양이 사진이 데이터셋의 i번째 데이터일 때, 이 고양이 사진을 넣은 결과물로 [3.2, 5.1, -1.7]의 벡터를 얻을 수 있었습니다. 이게 $f(x_i, W)$에 해당되고 이것을 스코어 벡터(Score Vector)라고 부릅니다. 


$$
L_i(f(x_i, W), y_i)
$$


다음으로, 분류기가 출력한 결과가 실제 정답과 비교했을 때 얼마나 잘하는지를 정량적으로 평가합니다. 이 과정으로 데이터셋의 모든 이미지들의 손실 값을 구한 다음 데이터 개수로 나눠 최종적인 평균 손실 값을 구합니다.


$$
L = \frac{1}{N}L_i(f(x_i, W), y_i)
$$


손실 값을 구하는 절차를 알아봤고, 이제 구체적인 손실 함수가 어떻게 생겨먹은 친구인지 알아봅니다.



#### SVM(Soft Vector Machine) Loss


$$
L_i = \sum_{j \neq y_i}\max(0, s_j - s_{y_i} + 1)
$$
위 수식은 다분류 문제에서 사용할 수 있도록 일반화된 SVM Loss입니다. 



![image-20250721141238094](/images/2025-07-20-CS231n_01/image-20250721141238094.png)



$0$과 $s_j - s_{y_i} + 1$ 중 큰 값을 선택하기 때문에 $s_j - s_{y_i} + 1$이 0보다 작아지기 전까지는 손실이 존재합니다. 그리고 $s_j - s_{y_i} + 1$는 $s_j(\text{정답이 아닌 레이블의 스코어}) + 1$와 $s_{y_i}(\text{정답 레이블의 스코어})$의 차이를 의미합니다. 따라서 정답 레이블의 스코어가 정답이 아닌 모든 레이블의 스코어보다 1 이상 차이가 존재할 때(더 클 때) 손실이 발생하지 않습니다.



#### Regularization





















